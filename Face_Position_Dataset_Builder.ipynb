{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Position Dataset Builder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/26medias/TF-Face-Angle-Translation/blob/master/Face_Position_Dataset_Builder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMKcGshGTWv1",
        "colab_type": "text"
      },
      "source": [
        "# Face Angle Dataset Generator\n",
        "\n",
        "We're going to download movie trailers from https://www.davestrailerpage.co.uk/\n",
        "\n",
        "The frames from the video files will be extracted and saved to file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf-UgvJOfYsQ",
        "colab_type": "text"
      },
      "source": [
        "## Downloading videos, extracting the frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaQniUZYTVWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "cellView": "code",
        "outputId": "2bf3470d-6457-4f84-fe3e-d5858b875880"
      },
      "source": [
        "import requests\n",
        "import ntpath\n",
        "import cv2\n",
        "import os, sys\n",
        "\n",
        "# The variables\n",
        "DIR_VIDEOS = \"videos\"\n",
        "DIR_IMAGES = \"images\"\n",
        "CAPTURE_FTP  = 10 # We'll extract 10 images per second of video\n",
        "\n",
        "if not os.path.isdir(DIR_VIDEOS):\n",
        "  os.mkdir(DIR_VIDEOS, 755);\n",
        "if not os.path.isdir(DIR_IMAGES):\n",
        "  os.mkdir(DIR_IMAGES, 755);\n",
        "\n",
        "# The methods\n",
        "# Dowload a video from a url\n",
        "def downloadFile(url):\n",
        "  myfile = requests.get(url)\n",
        "  filename = DIR_VIDEOS+\"/\"+ntpath.basename(url)\n",
        "  open(filename, 'wb').write(myfile.content)\n",
        "  return filename\n",
        "\n",
        "# Export the frames out of a video at a specific fps\n",
        "def videoToImages(filename, capture_fps=1):\n",
        "  basename = os.path.splitext(ntpath.basename(filename))[0]\n",
        "  print(\"basename:\", basename)\n",
        "  if not os.path.isdir(DIR_VIDEOS):\n",
        "    os.mkdir(DIR_IMAGES+\"/\"+basename, 755)\n",
        "  cap = cv2.VideoCapture(filename)\n",
        "  # Get the video's FPS\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  # How many frames between capture?\n",
        "  skipFrame = round(fps/capture_fps)\n",
        "  print(basename, \": fps: \",fps,\" / skipFrame: \", skipFrame)\n",
        "  i = 0\n",
        "  while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "      if ret == False:\n",
        "          break\n",
        "      i+=1\n",
        "      if (i % skipFrame == 0):\n",
        "        continue\n",
        "      cv2.imwrite(DIR_IMAGES+\"/\"+basename+'/'+str(round((i-1)/fps,2))+'sec.jpg',frame)\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  print(basename, \" processed.\")\n",
        "\n",
        "# Download a video then extract the frames\n",
        "def remoteVideoToImages(url):\n",
        "  videoFilename = downloadFile(url)\n",
        "  videoToImages(videoFilename, CAPTURE_FTP)\n",
        "\n",
        "remoteVideoToImages(\"http://trailers.apple.com/movies/fox_searchlight/lucy-in-the-sky/lucy-in-the-sky-trailer-1_h480p.mov\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basename: lucy-in-the-sky-trailer-1_h480p\n",
            "lucy-in-the-sky-trailer-1_h480p : fps:  23.976023976023978  / skipFrame:  2\n",
            "lucy-in-the-sky-trailer-1_h480p  processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFDgu312fjEW",
        "colab_type": "text"
      },
      "source": [
        "## Find & extract the faces from the video frames\n",
        "\n",
        "Import the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh6jYWfSiWhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "265bea5f-0fc1-451c-a6e3-058a75a5d52f"
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "!pip show keras-vggface\n",
        "!pip install matplotlib\n",
        "!pip install mtcnn"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-s9sk1ryg\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-s9sk1ryg\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-vggface==0.6 from git+https://github.com/rcmalli/keras-vggface.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (4.3.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface==0.6) (0.46)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=9ca6aa9c36728746714cd2e9a3b3583c2e05418f4b95e66781f4925bd6b10764\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4mehs8sa/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Name: keras-vggface\n",
            "Version: 0.6\n",
            "Summary: VGGFace implementation with Keras framework\n",
            "Home-page: https://github.com/rcmalli/keras-vggface\n",
            "Author: Refik Can MALLI\n",
            "Author-email: mallir@itu.edu.tr\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: pyyaml, pillow, six, numpy, h5py, keras, scipy\n",
            "Required-by: \n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/c7/8546b18fbd367b156c5bbbbaa8912ab31c8129171523ff8b47b546d70b09/mtcnn-0.0.9.tar.gz (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mtcnn\n",
            "  Building wheel for mtcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtcnn: filename=mtcnn-0.0.9-cp36-none-any.whl size=2257690 sha256=40023f082a0fa770f66b83a13d659bc0de526506eac54891314d4a7359043ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/81/65/6363fa5aafd7a155c896591e0c7c6e27b69642aa82b9cbf076\n",
            "Successfully built mtcnn\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGIkOVzijmPI",
        "colab_type": "text"
      },
      "source": [
        "We're going to use VGGFace2 to find & extract the faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ju5g7wfvJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as pyplot\n",
        "import glob\n",
        "import keras_vggface\n",
        "import mtcnn\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from pathlib import Path\n",
        "\n",
        "# The variables\n",
        "DIR_FACES = \"faces\"\n",
        "\n",
        "if not os.path.isdir(DIR_FACES):\n",
        "  os.mkdir(DIR_FACES, 755);\n",
        "\n",
        "# The methods\n",
        "# Get the directory of a filename\n",
        "def getDir(filename):\n",
        "  p = Path(filename);\n",
        "  return p.parts[len(p.parts)-2]\n",
        "\n",
        "# Extract a single face from an image\n",
        "def findFaces(filename):\n",
        "\t# load image from file\n",
        "\tpixels = pyplot.imread(filename)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\treturn (pixels, detector.detect_faces(pixels))\n",
        "\n",
        "def extractFaceFromImage(filename, required_size=(224, 224)):\n",
        "  (pixels, results) = findFaces(filename)\n",
        "  faces = []\n",
        "  for i,faceData in enumerate(results):\n",
        "    x1, y1, width, height = faceData['box']\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = asarray(image)\n",
        "    faces.append(face_array)\n",
        "  return faces;\n",
        "\n",
        "\n",
        "# Extract faces from images in a directory & its subdirectories\n",
        "def extractFacesFromDirectory(directory, outputDirectory):\n",
        "  filenames = glob.glob(directory+'/*/*.jpg')\n",
        "  for i,filename in enumerate(filenames):\n",
        "    dirname  = getDir(filename)\n",
        "    basename = os.path.splitext(ntpath.basename(filename))[0]\n",
        "    faces = extractFaceFromImage(filename);\n",
        "    print(filename, \"Faces: \", len(faces))\n",
        "    if len(faces) > 0:\n",
        "      n = 0\n",
        "      for face in faces:\n",
        "        im = Image.fromarray(face)\n",
        "        im.save(outputDirectory+'/'+dirname+'_'+basename+'-'+str(n)+'.jpg')\n",
        "        n = n+1\n",
        "\n",
        "extractFacesFromDirectory(DIR_IMAGES, DIR_FACES)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmmZ0K8StSNH",
        "colab_type": "text"
      },
      "source": [
        "## Cluster the faces\n",
        "\n",
        "We want to group all the actors per directory"
      ]
    }
  ]
}