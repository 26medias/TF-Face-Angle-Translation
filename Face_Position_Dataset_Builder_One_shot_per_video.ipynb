{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Position Dataset Builder - One-shot per video.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/26medias/TF-Face-Angle-Translation/blob/master/Face_Position_Dataset_Builder_One_shot_per_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMKcGshGTWv1",
        "colab_type": "text"
      },
      "source": [
        "# Face Angle Dataset Generator\n",
        "\n",
        "\n",
        "## Credits\n",
        "\n",
        "Face extraction built thanks to https://machinelearningmastery.com/how-to-perform-face-recognition-with-vggface2-convolutional-neural-network-in-keras/\n",
        "\n",
        "## How this works\n",
        "\n",
        "1. Download movie trailers\n",
        "2. Extract the frames from the video files\n",
        "3. Extract the faces from the images\n",
        "4. Cluster the faces by actor\n",
        "5. Build & save the facial landmarks for each face\n",
        "6. Build the dataset\n",
        "7. Zip & upload the dataset to Google Storage\n",
        "\n",
        "## Downloading videos, extracting the frames\n",
        "\n",
        "We're going to download movie trailers from https://www.davestrailerpage.co.uk/\n",
        "\n",
        "The frames from the video files will be extracted and saved to file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf-UgvJOfYsQ",
        "colab_type": "text"
      },
      "source": [
        "## Code setup: Imports & methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LybUqjyadTEJ",
        "colab_type": "text"
      },
      "source": [
        "Pip install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9J7chDuJwkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r Faces\n",
        "!rm -r faces\n",
        "!rm -r images\n",
        "!rm -r videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNuNNoUEdR6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "730a919e-6ebf-4aab-d92a-fefee1cd8582"
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "!pip show keras-vggface\n",
        "!pip install matplotlib\n",
        "!pip install mtcnn\n",
        "!pip install bs4\n",
        "!pip install selenium"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-zijhslwx\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-zijhslwx\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-vggface==0.6 from git+https://github.com/rcmalli/keras-vggface.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (4.3.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface==0.6) (0.46)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=3b0eb903920e5fc30a244641226742c7b797a0040b121328f6b7138642d6a871\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-st88y6zn/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Name: keras-vggface\n",
            "Version: 0.6\n",
            "Summary: VGGFace implementation with Keras framework\n",
            "Home-page: https://github.com/rcmalli/keras-vggface\n",
            "Author: Refik Can MALLI\n",
            "Author-email: mallir@itu.edu.tr\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: h5py, numpy, pillow, keras, six, scipy, pyyaml\n",
            "Required-by: \n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.6/dist-packages (0.0.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BfU4qFBdSdo",
        "colab_type": "text"
      },
      "source": [
        "### Code\n",
        "\n",
        "#### Directory Structure\n",
        "\n",
        "- Videos\n",
        "  - [video_filename]\n",
        "- Faces\n",
        "  - Clustered\n",
        "    - [group_id]\n",
        "      - ...faces\n",
        "  - Sources\n",
        "    - [video_filename]\n",
        "      - ...faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG07_79NwDPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD7jzfOIIJns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d1f24be3-3093-47fd-94ad-d607337cadab"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "import time\n",
        "import requests\n",
        "import ntpath\n",
        "import cv2\n",
        "import math\n",
        "import os, sys\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from scipy.spatial.distance import cosine\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import keras_vggface\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "import glob\n",
        "import mtcnn\n",
        "from pathlib import Path\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from scipy.cluster import  hierarchy\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "\n",
        "# create the detector, using default weights\n",
        "print(\"Creating the detector model\")\n",
        "detector = MTCNN()\n",
        "\n",
        "# create a vggface model\n",
        "print(\"Creating the face embedding model\")\n",
        "embedding_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\n",
        "# The variables\n",
        "DIR_VIDEOS = \"Videos\"\n",
        "DIR_FACES = \"Faces\"\n",
        "CAPTURE_FPS  = 23 # We'll extract 1 images per second of video\n",
        "\n",
        "if not os.path.isdir(DIR_VIDEOS):\n",
        "  os.mkdir(DIR_VIDEOS, 755);\n",
        "if not os.path.isdir(DIR_FACES):\n",
        "  os.mkdir(DIR_FACES, 755);\n",
        "if not os.path.isdir(DIR_FACES+\"/Clustered\"):\n",
        "  os.mkdir(DIR_FACES+\"/Clustered\", 755);\n",
        "if not os.path.isdir(DIR_FACES+\"/Sources\"):\n",
        "  os.mkdir(DIR_FACES+\"/Sources\", 755);\n",
        "if not os.path.isdir(DIR_FACES+\"/Previews\"):\n",
        "  os.mkdir(DIR_FACES+\"/Previews\", 755);"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the detector model\n",
            "Creating the face embedding model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaQniUZYTVWk",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# The methods\n",
        "# ===========\n",
        "\n",
        "# Colab progress bar\n",
        "def progress(value, max=100):\n",
        "    return HTML('<progress value=\"{value}\" max=\"{max}\" style=\"width: 50%\"> {value}</progress>'.format(value=value, max=max))\n",
        "\n",
        "# Get the directory of a filename\n",
        "def getDir(filename):\n",
        "  p = Path(filename);\n",
        "  return p.parts[len(p.parts)-2]\n",
        "\n",
        "# Dowload a video from a url\n",
        "def downloadFile(url):\n",
        "  print(\"Downloading \", url)\n",
        "  filename = DIR_VIDEOS+\"/\"+ntpath.basename(url)\n",
        "  if os.path.exists(filename):\n",
        "    return filename\n",
        "  myfile = requests.get(url)\n",
        "  open(filename, 'wb').write(myfile.content)\n",
        "  print(filename,\" downloaded.\")\n",
        "  return filename\n",
        "\n",
        "def imageFilesToGrid(directory, outputFilename):\n",
        "  filenames = glob.glob(directory+'/*.jpg')\n",
        "  print(directory, \": \", len(filenames), \" images\")\n",
        "  if len(filenames) < 4:\n",
        "    return False\n",
        "  result_figsize_resolution = 10 # 1 = 100px\n",
        "  \n",
        "  images_count = len(filenames)\n",
        "  # Calculate the grid size:\n",
        "  grid_size = math.ceil(math.sqrt(images_count))\n",
        "  \n",
        "  # Create plt plot:\n",
        "  fig, axes = pyplot.subplots(grid_size, grid_size, figsize=(result_figsize_resolution, result_figsize_resolution))\n",
        "  \n",
        "  current_file_number = 0\n",
        "  for image_filename in filenames:\n",
        "      x_position = current_file_number % grid_size\n",
        "      y_position = current_file_number // grid_size\n",
        "      plt_image = pyplot.imread(image_filename)\n",
        "      axes[x_position, y_position].imshow(plt_image)\n",
        "      current_file_number += 1\n",
        "  pyplot.subplots_adjust(left=0.0, right=1.0, bottom=0.0, top=1.0)\n",
        "  pyplot.savefig(outputFilename)\n",
        "  #pyplot.show()\n",
        "\n",
        "def exportImageGrids(directory, outputDirectory):\n",
        "  print(\"Exporting image grids...\")\n",
        "  dirs = os.listdir(directory)\n",
        "  dirs.sort()\n",
        "  ndirs = len(dirs)\n",
        "  for n,dir in enumerate(dirs):\n",
        "    if dir is not \"ALL\":\n",
        "      imageFilesToGrid(directory+\"/\"+dir, outputDirectory+\"/\"+dir+\".jpg\");\n",
        "    progress(n, ndirs)\n",
        "\n",
        "# Extract the faces from an image, return an array of numpy faces\n",
        "def extractFacesFromImage(pixels, required_size=(224, 224), limit=50):\n",
        "  results = detector.detect_faces(pixels)\n",
        "  faces = []\n",
        "  errors = 0\n",
        "  for i,faceData in enumerate(results):\n",
        "    if len(faces) > limit:\n",
        "      break\n",
        "    x1, y1, width, height = faceData['box']\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    try:\n",
        "      image = Image.fromarray(face)\n",
        "      image = image.resize(required_size)\n",
        "      face_array = asarray(image)\n",
        "      faces.append(face_array)\n",
        "      if limit==1:\n",
        "        return face_array\n",
        "    except:\n",
        "      errors+=1\n",
        "  if limit==1 and len(faces)==0:\n",
        "    return False\n",
        "  return faces;\n",
        "\n",
        "\n",
        "# Export the frames out of a video at a specific fps\n",
        "def videoToFaces(filename, skipFrame=10, maxFrame=0):\n",
        "  print(\"Extracting faces from the video frames...\")\n",
        "  basename = os.path.splitext(ntpath.basename(filename))[0]\n",
        "  #print(\"basename:\", basename)\n",
        "  cap = cv2.VideoCapture(filename)\n",
        "  # Get the video's FPS\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  print(basename, \": fps: \",fps, \" Frames: \", nframes)\n",
        "  out = display(progress(0, nframes), display_id=True)\n",
        "  i = 0\n",
        "  c = 0\n",
        "  faces = []\n",
        "  while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "      if ret == False:\n",
        "          break\n",
        "      i+=1\n",
        "      out.update(progress(i, nframes))\n",
        "      if maxFrame>0 and i > maxFrame:\n",
        "        break;\n",
        "      if (i % skipFrame == 0):\n",
        "        continue\n",
        "      frameFaces = extractFacesFromImage(frame)\n",
        "      for f in frameFaces:\n",
        "        faces.append(f)\n",
        "        c+=1\n",
        "      #cv2.imwrite(DIR_IMAGES+\"/\"+basename+'/'+str(round((i-1)/fps,2))+'sec.jpg',frame)\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  print(basename, \" processed.\")\n",
        "  print(c,\"/\",i,\" frames analyzed.\")\n",
        "  print(len(faces), \" faces found.\")\n",
        "  return faces\n",
        "\n",
        "\n",
        "# Show a few images\n",
        "def showImages(images, width=4):\n",
        "  fig = pyplot.figure(figsize=(width, math.ceil(len(images)/width)))\n",
        "  for i in range(len(images)):\n",
        "      pyplot.subplot(width, math.ceil(len(images)/width), i+1)\n",
        "      pyplot.imshow(images[i])\n",
        "      pyplot.axis('off')\n",
        "  pyplot.savefig('preview.png')\n",
        "  pyplot.show()\n",
        "\n",
        "#Save an array of images to files\n",
        "def saveImages(images, dest, names=False, prefix=\"\", showProgress=True):\n",
        "  if not os.path.isdir(dest):\n",
        "    os.mkdir(dest, 755);\n",
        "  nImages = len(images)\n",
        "  if showProgress is True:\n",
        "    print(\"Saving \",nImages,\" images to \", dest)\n",
        "    out = display(progress(0, nImages), display_id=True)\n",
        "  for n, image in enumerate(images):\n",
        "    if names is False:\n",
        "      cv2.imwrite(dest+\"/\"+prefix+str(n)+'.jpg', image)\n",
        "    else:\n",
        "      cv2.imwrite(dest+\"/\"+prefix+str(names[n])+'.jpg', image)\n",
        "    if showProgress is True:\n",
        "      out.update(progress(n, nImages))\n",
        "      \n",
        "\n",
        "# Extract faces and calculate face embeddings for a list of photo files\n",
        "def get_embeddings(faces):\n",
        "  print(\"Calculating the embeddings...\")\n",
        "\t# convert into an array of samples\n",
        "  samples = asarray(faces, 'float32')\n",
        "  # prepare the face for the model, e.g. center pixels\n",
        "  samples = preprocess_input(samples, version=2)\n",
        "  # perform prediction\n",
        "  embeddings = embedding_model.predict(samples)\n",
        "  return embeddings\n",
        "\n",
        "\n",
        "# Determine if a candidate face is a match for a known face\n",
        "def is_match(known_embedding, candidate_embedding, threshold=0.5):\n",
        "  # calculate distance between embeddings\n",
        "  score = cosine(known_embedding, candidate_embedding)\n",
        "  return score >= threshold\n",
        "\n",
        "# Cluster the faces by cosine distance\n",
        "def clusterFaces(faces, embeddings):\n",
        "  groups = [] # Array of dict {faces:[], embeddings: []}\n",
        "  nFaces = len(faces)\n",
        "  print(\"Clustering \",nFaces,\" faces...\")\n",
        "  out = display(progress(0, nFaces), display_id=True)\n",
        "  # For each faces\n",
        "  for n, face in enumerate(faces):\n",
        "    out.update(progress(n, nFaces))\n",
        "    if len(groups)==0:\n",
        "      groups.append({\n",
        "        \"faces\":     [face],\n",
        "        \"names\":     [n],\n",
        "        \"embeddings\":[embeddings[n]]\n",
        "      })\n",
        "    else:\n",
        "      # Not the first face, match it against all the groups, see if the average of cosine distance match an existing face\n",
        "      scores = [] # array of dict {group: n, embeddings: []}\n",
        "      for g, group in enumerate(groups):\n",
        "        groupScores = []\n",
        "        for embedding in group[\"embeddings\"]:\n",
        "          groupScores.append(cosine(embedding, embeddings[n]))\n",
        "        score = np.mean(groupScores)\n",
        "        scores.append({\n",
        "            \"group\": g,\n",
        "            \"score\": score\n",
        "        })\n",
        "      # Sort the scores for each group by lowest score, check if that score is below the threshold\n",
        "      scores = sorted(scores, key = lambda i: i[\"score\"], reverse=False)\n",
        "      if scores[0][\"score\"] <= 0.5:\n",
        "        # Add to the existing group the face matches\n",
        "        groups[scores[0][\"group\"]][\"embeddings\"].append(embeddings[n])\n",
        "        groups[scores[0][\"group\"]][\"faces\"].append(face)\n",
        "        groups[scores[0][\"group\"]][\"names\"].append(n)\n",
        "        #print(\"[Matched] face #\", n, \" to group #\", scores[0][\"group\"], \"score:\", scores[0][\"score\"])\n",
        "      else:\n",
        "        groups.append({\n",
        "          \"faces\":     [face],\n",
        "          \"names\":     [n],\n",
        "          \"embeddings\":[embeddings[n]]\n",
        "        })\n",
        "        #print(\"[New face] face #\", n, \" / Best score:\", scores[0][\"score\"])\n",
        "  return groups;\n",
        "\n",
        "# Cluster all the faces from a remote video\n",
        "def clusterFacesOnVideo(url):\n",
        "  print(\"Processing \", url);\n",
        "  # Download the video\n",
        "  videoFilename = downloadFile(url)\n",
        "  \n",
        "  # Get the directories name for that video\n",
        "  dirname      = os.path.splitext(ntpath.basename(videoFilename))[0]\n",
        "  dirSources   = DIR_FACES+\"/Sources/\"+dirname\n",
        "  dirClustered = DIR_FACES+\"/Clustered/\"+dirname\n",
        "  dirPreviews  = DIR_FACES+\"/Previews/\"+dirname\n",
        "  \n",
        "  if os.path.exists(dirPreviews):\n",
        "    # Video already processed, go to the next one\n",
        "    print(\"Video already processed. Skipping.\")\n",
        "    return False\n",
        "  \n",
        "  # Create the directories\n",
        "  if not os.path.isdir(dirSources):\n",
        "    os.mkdir(dirSources, 755);\n",
        "  if not os.path.isdir(dirClustered):\n",
        "    os.mkdir(dirClustered, 755);\n",
        "  if not os.path.isdir(dirPreviews):\n",
        "    os.mkdir(dirPreviews, 755);\n",
        "  \n",
        "  # Find the faces on the video\n",
        "  faces        = videoToFaces(videoFilename, CAPTURE_FPS)\n",
        "  nFaces       = len(faces)\n",
        "  print(nFaces,\" faces detected\")\n",
        "  \n",
        "  # Save all the faces\n",
        "  saveImages(faces, dirSources, prefix=dirname+\"_\")\n",
        "  \n",
        "  # Get the embedding for all the faces\n",
        "  embeddings    = get_embeddings(faces)\n",
        "  \n",
        "  # Cluster the faces using cosine distance\n",
        "  clusters      = clusterFaces(faces, embeddings)\n",
        "  nClusters     = len(clusters)\n",
        "  \n",
        "  # Export each face group\n",
        "  print(\"Saving \",nClusters,\" face clusters...\")\n",
        "  for n, group in enumerate(clusters):\n",
        "    saveImages(group[\"faces\"], dirClustered+\"/\"+str(n), group[\"names\"], showProgress=False)\n",
        "  \n",
        "  # Build grids to show each face groups\n",
        "  exportImageGrids(dirClustered, dirPreviews)\n",
        "\n",
        "\n",
        "def clusterFacesFromVideos(urls):\n",
        "  nUrls = len(urls)\n",
        "  for n,url in enumerate(urls):\n",
        "    clusterFacesOnVideo(url)\n",
        "\n",
        "def fetchAllHDVideos(url):\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.content, \"html5lib\")\n",
        "  links = soup.find_all('a')\n",
        "  videos = []\n",
        "  for tag in links:\n",
        "    link = tag.get('href', None)\n",
        "    if link is not None and 'h1080p' in link:\n",
        "      videos.append(link)\n",
        "  return videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLgQisTn9epT",
        "colab_type": "text"
      },
      "source": [
        "## Execute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wArceY3F9eIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0fee6e6d-c5d5-486e-80b8-65d46cd45b92"
      },
      "source": [
        "# Fetch all the HD trailers by webscrapping the webpage\n",
        "vids = fetchAllHDVideos(\"https://www.davestrailerpage.co.uk/\")\n",
        "\n",
        "# Cluster the faces from a bunch of videos\n",
        "clusterFacesFromVideos(vids)\n",
        "\n",
        "# Save the faces\n",
        "!tar -zcf faces.tar.gz Faces\n",
        "\n",
        "# Upload to Cloud Storage\n",
        "!gcloud config set project deep-learning-files\n",
        "!gsutil cp  ./faces.tar.gz gs://tf-face-angle-translation/datasets/faces-clustered-large.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing  http://trailers.apple.com/movies/paramount/terminator-dark-fate/terminator-dark-fate-trailer-2_h1080p.mov\n",
            "Downloading  http://trailers.apple.com/movies/paramount/terminator-dark-fate/terminator-dark-fate-trailer-2_h1080p.mov\n",
            "Extracting faces from the video frames...\n",
            "terminator-dark-fate-trailer-2_h1080p : fps:  23.976023976023978  Frames:  3774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<progress value=\"884\" max=\"3774\" style=\"width: 50%\"> 884</progress>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}