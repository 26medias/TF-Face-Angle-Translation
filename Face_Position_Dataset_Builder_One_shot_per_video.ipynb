{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Position Dataset Builder - One-shot per video.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/26medias/TF-Face-Angle-Translation/blob/master/Face_Position_Dataset_Builder_One_shot_per_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMKcGshGTWv1",
        "colab_type": "text"
      },
      "source": [
        "# Face Angle Dataset Generator\n",
        "\n",
        "\n",
        "## Credits\n",
        "\n",
        "Face extraction built thanks to https://machinelearningmastery.com/how-to-perform-face-recognition-with-vggface2-convolutional-neural-network-in-keras/\n",
        "\n",
        "## How this works\n",
        "\n",
        "1. Download movie trailers\n",
        "2. Extract the frames from the video files\n",
        "3. Extract the faces from the images\n",
        "4. Cluster the faces by actor\n",
        "5. Build & save the facial landmarks for each face\n",
        "6. Build the dataset\n",
        "7. Zip & upload the dataset to Google Storage\n",
        "\n",
        "## Downloading videos, extracting the frames\n",
        "\n",
        "We're going to download movie trailers from https://www.davestrailerpage.co.uk/\n",
        "\n",
        "The frames from the video files will be extracted and saved to file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf-UgvJOfYsQ",
        "colab_type": "text"
      },
      "source": [
        "## Code setup: Imports & methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LybUqjyadTEJ",
        "colab_type": "text"
      },
      "source": [
        "Pip install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNuNNoUEdR6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "outputId": "4f33b3df-3098-4dc8-ca33-e8c0f3231a39"
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "!pip show keras-vggface\n",
        "!pip install matplotlib\n",
        "!pip install mtcnn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-8xmundr0\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-8xmundr0\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (4.3.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface==0.6) (0.46)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=5596731204f2ce9269abff348bd52d56d99a768cd98f26750e00741fec025ca0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rw8xlel4/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Name: keras-vggface\n",
            "Version: 0.6\n",
            "Summary: VGGFace implementation with Keras framework\n",
            "Home-page: https://github.com/rcmalli/keras-vggface\n",
            "Author: Refik Can MALLI\n",
            "Author-email: mallir@itu.edu.tr\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: numpy, pillow, six, pyyaml, h5py, scipy, keras\n",
            "Required-by: \n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/c7/8546b18fbd367b156c5bbbbaa8912ab31c8129171523ff8b47b546d70b09/mtcnn-0.0.9.tar.gz (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 31.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mtcnn\n",
            "  Building wheel for mtcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtcnn: filename=mtcnn-0.0.9-cp36-none-any.whl size=2257690 sha256=c945ccbedff031413f1f63181ffb8d94c4e11582db363a49ad6aa5cd7fba0124\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/81/65/6363fa5aafd7a155c896591e0c7c6e27b69642aa82b9cbf076\n",
            "Successfully built mtcnn\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BfU4qFBdSdo",
        "colab_type": "text"
      },
      "source": [
        "Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG07_79NwDPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r faces/0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaQniUZYTVWk",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import ntpath\n",
        "import cv2\n",
        "import math\n",
        "import os, sys\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from scipy.spatial.distance import cosine\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import keras_vggface\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "import glob\n",
        "import mtcnn\n",
        "from pathlib import Path\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from scipy.cluster import  hierarchy\n",
        "\n",
        "# create the detector, using default weights\n",
        "detector = MTCNN()\n",
        "\n",
        "# create a vggface model\n",
        "embedding_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\n",
        "# The variables\n",
        "DIR_VIDEOS = \"videos\"\n",
        "DIR_IMAGES = \"images\"\n",
        "DIR_FACES = \"faces\"\n",
        "CAPTURE_FPS  = 23*20 # We'll extract 30 images per second of video\n",
        "\n",
        "if not os.path.isdir(DIR_VIDEOS):\n",
        "  os.mkdir(DIR_VIDEOS, 755);\n",
        "if not os.path.isdir(DIR_IMAGES):\n",
        "  os.mkdir(DIR_IMAGES, 755);\n",
        "if not os.path.isdir(DIR_FACES):\n",
        "  os.mkdir(DIR_FACES, 755);\n",
        "\n",
        "# The methods\n",
        "# ===========\n",
        "\n",
        "# Get the directory of a filename\n",
        "def getDir(filename):\n",
        "  p = Path(filename);\n",
        "  return p.parts[len(p.parts)-2]\n",
        "# Dowload a video from a url\n",
        "def downloadFile(url):\n",
        "  myfile = requests.get(url)\n",
        "  filename = DIR_VIDEOS+\"/\"+ntpath.basename(url)\n",
        "  open(filename, 'wb').write(myfile.content)\n",
        "  return filename\n",
        "\n",
        "\n",
        "# Extract the faces from an image, return an array of numpy faces\n",
        "def extractFacesFromImage(pixels, required_size=(224, 224), limit=50):\n",
        "  results = detector.detect_faces(pixels)\n",
        "  faces = []\n",
        "  for i,faceData in enumerate(results):\n",
        "    if len(faces) > limit:\n",
        "      break\n",
        "    x1, y1, width, height = faceData['box']\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    try:\n",
        "      image = Image.fromarray(face)\n",
        "      image = image.resize(required_size)\n",
        "      face_array = asarray(image)\n",
        "      faces.append(face_array)\n",
        "      if limit==1:\n",
        "        return face_array\n",
        "    except:\n",
        "      print(\"Face processing failed\")\n",
        "  if limit==1 and len(faces)==0:\n",
        "    return False\n",
        "  return faces;\n",
        "\n",
        "\n",
        "# Export the frames out of a video at a specific fps\n",
        "def videoToFaces(filename, skipFrame=10):\n",
        "  basename = os.path.splitext(ntpath.basename(filename))[0]\n",
        "  print(\"basename:\", basename)\n",
        "  if not os.path.isdir(DIR_IMAGES+\"/\"+basename):\n",
        "    os.mkdir(DIR_IMAGES+\"/\"+basename, 755)\n",
        "  cap = cv2.VideoCapture(filename)\n",
        "  # Get the video's FPS\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  print(basename, \": fps: \",fps,\" / skipFrame: \", skipFrame)\n",
        "  i = 0\n",
        "  c = 0\n",
        "  faces = []\n",
        "  while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "      if ret == False:\n",
        "          break\n",
        "      i+=1\n",
        "      if (i % skipFrame == 0):\n",
        "        continue\n",
        "      frameFaces = extractFacesFromImage(frame)\n",
        "      for f in frameFaces:\n",
        "        faces.append(f)\n",
        "        c+=1\n",
        "      #cv2.imwrite(DIR_IMAGES+\"/\"+basename+'/'+str(round((i-1)/fps,2))+'sec.jpg',frame)\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  print(basename, \" processed.\")\n",
        "  print(c,\"/\",i,\" frames analyzed.\")\n",
        "  print(len(faces), \" faces found.\")\n",
        "  return faces\n",
        "\n",
        "\n",
        "# Show a few images\n",
        "def showImages(images, width=4):\n",
        "  fig = pyplot.figure(figsize=(width, math.ceil(len(images)/width)))\n",
        "  for i in range(len(images)):\n",
        "      pyplot.subplot(width, math.ceil(len(images)/width), i+1)\n",
        "      pyplot.imshow(images[i])\n",
        "      pyplot.axis('off')\n",
        "  pyplot.savefig('preview.png')\n",
        "  pyplot.show()\n",
        "\n",
        "#Save an array of images to files\n",
        "def saveImages(images, dest):\n",
        "  for n, image in enumerate(images):\n",
        "    cv2.imwrite(dest+\"/\"+str(n)+'.jpg', image)\n",
        "\n",
        "# Extract faces and calculate face embeddings for a list of photo files\n",
        "def get_embeddings(faces):\n",
        "\t# convert into an array of samples\n",
        "\tsamples = asarray(faces, 'float32')\n",
        "\t# prepare the face for the model, e.g. center pixels\n",
        "\tsamples = preprocess_input(samples, version=2)\n",
        "\t# perform prediction\n",
        "\tembeddings = embedding_model.predict(samples)\n",
        "\treturn embeddings\n",
        "\n",
        "\n",
        "# Determine if a candidate face is a match for a known face\n",
        "def is_match(known_embedding, candidate_embedding, threshold=0.5):\n",
        "\t# calculate distance between embeddings\n",
        "\tscore = cosine(known_embedding, candidate_embedding)\n",
        "\treturn score >= threshold\n",
        "\n",
        "# Cluster the faces by cosine distance\n",
        "def clusterFaces(faces, embeddings):\n",
        "  print(\"Clustering the faces...\")\n",
        "  groups = []\n",
        "  for n, face in enumerate(faces):\n",
        "    if len(groups)==0:\n",
        "      print(\"First face in the cluster\")\n",
        "      groups.append({\n",
        "        \"faces\":     [face],\n",
        "        \"embeddings\":[embeddings[n]]\n",
        "      })\n",
        "    else:\n",
        "      scores = []\n",
        "      for g, group in enumerate(groups):\n",
        "        for embedding in group[\"embeddings\"]:\n",
        "          scores.append(cosine(embedding, embeddings[n]))\n",
        "        score = np.mean(scores)\n",
        "        #print(\"face #\", n, \" group #\", g, \"score:\", score)\n",
        "        scores.append({\n",
        "            \"group\": g,\n",
        "            \"score\": score\n",
        "        })\n",
        "      scores = sorted(scores, key = lambda i: i[\"score\"], reverse=True) \n",
        "      print(\"face #\", n, \" group #\", scores[0].group, \"score:\", scores[0].score)\n",
        "      if scores[0][\"score\"] >= 0.6:\n",
        "        groups[scores[0].group][\"embeddings\"].append(embeddings[n])\n",
        "        groups[scores[0].group][\"faces\"].append(face)\n",
        "      else:\n",
        "        groups.append({\n",
        "          \"faces\":     [face],\n",
        "          \"embeddings\":[embeddings[n]]\n",
        "        })\n",
        "  return groups;\n",
        "\n",
        "# Cluster all the faces from a remote video\n",
        "def clusterFacesOnVideo(url):\n",
        "  videoFilename = downloadFile(url)\n",
        "  faces         = videoToFaces(videoFilename, CAPTURE_FPS)\n",
        "  \n",
        "  if not os.path.isdir(DIR_FACES+\"/ALL\"):\n",
        "    os.mkdir(DIR_FACES+\"/ALL\", 755);\n",
        "  #saveImages(faces, DIR_FACES+\"/ALL\")\n",
        "  \n",
        "  embeddings    = get_embeddings(faces)\n",
        "  clusters      = clusterFaces(faces, embeddings)\n",
        "  for n, group in enumerate(clusters):\n",
        "    if not os.path.isdir(DIR_FACES+\"/\"+str(n)):\n",
        "      os.mkdir(DIR_FACES+\"/\"+str(n), 755);\n",
        "    saveImages(group[\"faces\"], DIR_FACES+\"/\"+str(n))\n",
        "  #showImages(faces)\n",
        "\n",
        "#remoteVideoToImages(\"http://trailers.apple.com/movies/paramount/terminator-dark-fate/terminator-dark-fate-trailer-2_h480p.mov\")\n",
        "#extractFacesFromDirectory(DIR_IMAGES, DIR_FACES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGyzfOZ1wuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2d33f47-7866-4257-dda7-9f3758059ad3"
      },
      "source": [
        "scores = []\n",
        "for i in range(5):\n",
        "  scores.append({\n",
        "      \"i\": i,\n",
        "      \"v\": i*5\n",
        "  })\n",
        "scores = sorted(scores, key = lambda i: i['i'], reverse=False) \n",
        "print(scores)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'i': 0, 'v': 0}, {'i': 1, 'v': 5}, {'i': 2, 'v': 10}, {'i': 3, 'v': 15}, {'i': 4, 'v': 20}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah3WRRU9c7Qr",
        "colab_type": "text"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRWfL4YHc6xg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "95bae9f4-a6be-4922-d407-84c3d3b30885"
      },
      "source": [
        "clusterFacesOnVideo(\"http://trailers.apple.com/movies/paramount/terminator-dark-fate/terminator-dark-fate-trailer-2_h480p.mov\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basename: terminator-dark-fate-trailer-2_h480p\n",
            "terminator-dark-fate-trailer-2_h480p : fps:  23.976023976023978  / skipFrame:  460\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "Face processing failed\n",
            "terminator-dark-fate-trailer-2_h480p  processed.\n",
            "1044 / 3774  frames analyzed.\n",
            "1044  faces found.\n",
            "Clustering the faces...\n",
            "First face in the cluster\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-21674039a93a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclusterFacesOnVideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://trailers.apple.com/movies/paramount/terminator-dark-fate/terminator-dark-fate-trailer-2_h480p.mov\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-c02b3da29d4d>\u001b[0m in \u001b[0;36mclusterFacesOnVideo\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0membeddings\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m   \u001b[0mclusters\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mclusterFaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR_FACES\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-c02b3da29d4d>\u001b[0m in \u001b[0;36mclusterFaces\u001b[0;34m(faces, embeddings)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         })\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"face #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" group #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-c02b3da29d4d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         })\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"face #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" group #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcphGd67VQOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zcvf faces.tar.gz faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnBt15v8VyqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Veur9BaIV6u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud config set project deep-learning-files\n",
        "#!gsutil cp gs://tf-face-angle-translation/foo.bar ./foo.bar\n",
        "!gsutil cp  ./faces.tar.gz gs://tf-face-angle-translation/datasets/faces-terminator.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}